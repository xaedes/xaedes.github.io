<!DOCTYPE html>
<html>
<title>Kalman-Filter</title>
<link rel="stylesheet" href="lib/highlight-styles/vs.css">


<xmp theme="spacelab" style="display:none;" toc="true" >

[Back to index](index.html)


# Kalman-Filter (KF)

State is modelled with normal distributions.
State transition over time is modelled as linear operations on state and normal distributed control variables.
Observations are incorporated in the state estimation with a linear model linking observations and state.

## system model

| Symbol          | Shape                      | Description                                      |
| -------         | ---                        | ------------                                     |
| $\pmb{x}$       | $\mathbb{R}^{N \times 1}$  | system state vector                              |
| $\hat{\pmb{x}}$ | $\mathbb{R}^{N \times 1}$  | state estimation                                 |
| $\pmb{P}$       | $\mathbb{R}^{N \times N}$  | state estimation error covariance matrix         |
| $\pmb{F}$       | $\mathbb{R}^{N \times N}$  | system dynamic state transition matrix           |
| $\pmb{Q}$       | $\mathbb{R}^{N \times N}$  | prediction covariance                            |
| $\pmb{u}$       | $\mathbb{R}^{K \times 1}$  | external system input vector (e.g. user control) |
| $\pmb{B}$       | $\mathbb{R}^{N \times K}$  | external input state dynamic                     |
| $\pmb{z}$       | $\mathbb{R}^{M \times 1}$  | observation vector                               |
| $\pmb{H}$       | $\mathbb{R}^{N \times M}$  | observation matrix transforms a state vector to a observation vector |
| $\pmb{R}$       | $\mathbb{R}^{M \times M}$  | observation error covariance matrix              |


$N$ number of states

$M$ number of observations

$K$ number of external system inputs (often controls)

<br/ >

The process model describes how the state varies over time.

$\textbf{process model:} (\pmb{F}, \pmb{B}, \pmb{x}_k, \pmb{P}_k, \pmb{u}_k) \mapsto (\pmb{x}_{k+1}) $

$\pmb{x}_{k+1} =  \pmb{F} \cdot \pmb{x}_k + \pmb{B} \cdot \pmb{u}_k + \pmb{v} $

$\pmb{v}$ is zero mean normal distributed noise.

$\pmb{v} \sim N(0,\pmb{Q})$


[Input control noise is encoded in prediction covariance.](https://stats.stackexchange.com/questions/134920/kalman-filter-with-input-control-noise)
The prediction covariance $\pmb{Q}$ contains state transition covariance $\pmb{Q}_{F}$ and external input dynamic covariance $\pmb{Q}_{B}$:

$\pmb{v}_{F} \sim N(0,\pmb{Q}_{F})$

$\pmb{v}_{B} \sim N(0,\pmb{Q}_{B})$

$\pmb{v} = \pmb{v}_{F} + \pmb{v}_{B}$

$\pmb{Q} = \pmb{Q}_{F} + \pmb{B} \cdot \pmb{Q}_{B} \cdot \pmb{B}^T$

$\pmb{Q}_{F} \in \mathbb{R}^{N \times N}$, $\pmb{Q}_{B} \in \mathbb{R}^{N \times K}$

$\pmb{x}_{k+1} =  \pmb{F} \cdot \pmb{x}_k + \pmb{v}_{F} + \pmb{B} \cdot \pmb{u}_k + \pmb{v}_{B} $

<br/ >

The observation model describes an observation in terms of the state:

$\textbf{observation model:}$ $(\pmb{H}, \pmb{x}_k) \mapsto (\widetilde{\pmb{z}}_{k}) $

$\widetilde{\pmb{z}}_{k} = \pmb{H} \cdot \pmb{x}_{k} + \pmb{u}$

$\pmb{u}$ models zero mean normal distributed measurement noise.

$\pmb{u} \sim N(0,\pmb{R})$

<br/ >

## filter equations
A kalman filter is a 7-tuple with transition matrices, their covariance matrices, an estimated state and its covariance matrix:

$\textbf{KalmanFilter:}$ $(\pmb{F}, \pmb{B}, \pmb{Q}, \pmb{H}, \pmb{R}, \hat{\pmb{x}}, \pmb{P})$

<br/ >

__NOTE__: prediction and observation here happen at different steps $k$. The time associated with each step can be different, but strictly monotous increasing with $k$. This makes it easy to use the same equations for equally spaced timesteps with simple predict & observe iterations on measurement as well as for varying timestep and interleaved predict and observe operations.

<br/ >

$\textbf{initial condition:}$ $(\pmb{x}_0, \pmb{P}_0)$

<br/ >

$\textbf{predict:}$ $(\pmb{F}, \pmb{B}, \hat{\pmb{x}_k}, \pmb{P}_k, \pmb{u}_k) \mapsto (\hat{\pmb{x}}_{k+1}, \pmb{P}_{k+1}) $

$\hat{\pmb{x}}_{k+1} = \pmb{F} \cdot \hat{\pmb{x}_k} + \pmb{B} \cdot \pmb{u}_k$

$\pmb{P}_{k+1} = \pmb{F} \cdot \pmb{P}_k \cdot \pmb{F}^T + \pmb{Q}$

<br/ >
$\textbf{observe:}$ $(\pmb{H}, \hat{\pmb{x}_k}, \pmb{P}_k, \pmb{z}_k) \mapsto (\hat{\pmb{x}}_{k+1}, \pmb{P}_{k+1}) $

innovation: 
$\pmb{w} = \pmb{z}_k - \pmb{H} \cdot \hat{\pmb{x}}_k$

$\pmb{w} \in \mathbb{R}^{M \times 1}$

residual covariance:
$\pmb{S} = \pmb{H} \cdot \pmb{P} \cdot \pmb{H}^T + \pmb{R}$

$\pmb{S} \in \mathbb{R}^{M \times M}$

kalman gain:
$\pmb{K} = \pmb{P} \cdot \pmb{H}^T \cdot \pmb{S}^{-1}$

$\pmb{K} = \frac{\pmb{P} \cdot \pmb{H}^T}{\pmb{S}}$

$\pmb{K} = \frac{\pmb{P} \cdot \pmb{H}^T}{\pmb{H} \cdot \pmb{P} \cdot \pmb{H}^T + \pmb{R}}$ weights the measurement covariance with the current state estimation covariance.

$\pmb{K} \in \mathbb{R}^{N \times M}$

$\hat{\pmb{x}}_{k+1} = \hat{\pmb{x}}_k + \pmb{K} \cdot \pmb{w}$

$\pmb{P}_{k+1} = \pmb{P}_k - \pmb{K} \cdot \pmb{S} \cdot \pmb{K}^T$

<br/ >

Due to numerical errors the computation of $\pmb{P}_{k+1}$ can result in invalid non-symmetrical covariance matrices.
To restore symmetry:

$\textbf{symmetrize:}$ $P_{symmetrical} = \frac{P + P^T}{2}$




## web links

- http://bilgin.esme.org/BitsAndBytes/KalmanFilterforDummies
- https://github.com/xaedes/Python-Extendend-Kalman-Filter/blob/master/Kalman.py
- https://stats.stackexchange.com/questions/134920/kalman-filter-with-input-control-noise
- https://en.wikipedia.org/wiki/Kalman_filter

german links:
- https://de.wikipedia.org/wiki/Kalman-Filter
- http://www.cbcity.de/das-kalman-filter-einfach-erklaert-teil-1
- https://www.ei.rub.de/media/ei/lehrmaterialien/120/a896a6a0b135530a8a00b094fa631b2ea0e1c95d/KalmanFolien.pdf

# Extended-Kalman-Filter (EKF)



# Information-Filter (IF)


[Back to index](index.html) &raquo;
[Back to top](#) 

</xmp>

<script src="lib/strapdown-zeta/strapdown.min.js"></script>
</html>
